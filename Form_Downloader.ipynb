{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import json\n",
    "import string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "\n",
    "language_to_QID = {\"AKK\" : \"Q35518\",\n",
    "                   \"AR\" : \"Q13955\",\n",
    "                   \"CS\" : \"Q9056\",\n",
    "                   \"DE\" : \"Q188\",\n",
    "                   \"EN\" : \"Q1860\",\n",
    "                   \"FR\" : \"Q150\",\n",
    "                   \"HE\" : \"Q9288\",\n",
    "                   \"HIT\" : \"Q35668\",\n",
    "                   \"IT\" : \"Q652\",\n",
    "                   \"RU\" : \"Q7737\",\n",
    "                   \"SUX\" : \"Q36790\",\n",
    "                   \"TR\" : \"Q256\",\n",
    "                   \"LA\" : \"Q397\"}\n",
    "\n",
    "def getShortLang(lang) :\n",
    "  ShortQuery1 = \"\"\"\n",
    "  # tool: ordia\n",
    "  # title: List of lexemes for a language\n",
    "  SELECT\n",
    "    ?lexeme ?lexemeLabel ?form ?formlabel\n",
    "    ?lexical_category ?lexical_categoryLabel\n",
    "  WITH {\n",
    "    SELECT ?lexeme (GROUP_CONCAT(DISTINCT ?lexemeLab; SEPARATOR = \" // \") AS ?lexemeLabel) ?lexical_category ?form (GROUP_CONCAT(DISTINCT ?formLab; SEPARATOR = \" // \") AS ?formlabel) WHERE {\n",
    "      ?lexeme a ontolex:LexicalEntry ; \"\"\"\n",
    "\n",
    "  ShortQuery2 = f\"\"\"\n",
    "              dct:language wd:{language_to_QID.get(lang)} ;\n",
    "              wikibase:lemma ?lexemeLab .\"\"\"\n",
    "  ShortQuery3 = \"\"\"\n",
    "      OPTIONAL {\n",
    "        ?lexeme wikibase:lexicalCategory ?lexical_category .\n",
    "      }\n",
    "    ?lexeme ontolex:lexicalForm ?form .\n",
    "    ?form ontolex:representation ?formLab .\n",
    "    }Group by ?lexeme ?lexical_category ?form\n",
    "  } AS %results\n",
    "  WHERE {\n",
    "    INCLUDE %results\n",
    "    OPTIONAL {\n",
    "      ?lexical_category rdfs:label ?lexical_categoryLabel .\n",
    "      FILTER (LANG(?lexical_categoryLabel) = \"en\")\n",
    "    }\n",
    "    # SERVICE does not work!?\n",
    "    # SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" . }\n",
    "  }\n",
    "    \"\"\"\n",
    "  return ShortQuery1 + ShortQuery2 + ShortQuery3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  # tool: ordia\n",
      "  # title: List of lexemes for a language\n",
      "  SELECT\n",
      "    ?lexeme ?lexemeLabel ?form ?formlabel\n",
      "    ?lexical_category ?lexical_categoryLabel\n",
      "  WITH {\n",
      "    SELECT ?lexeme (GROUP_CONCAT(DISTINCT ?lexemeLab; SEPARATOR = \" // \") AS ?lexemeLabel) ?lexical_category ?form (GROUP_CONCAT(DISTINCT ?formLab; SEPARATOR = \" // \") AS ?formlabel) WHERE {\n",
      "      ?lexeme a ontolex:LexicalEntry ; \n",
      "              dct:language wd:Q36790 ;\n",
      "              wikibase:lemma ?lexemeLab .\n",
      "      OPTIONAL {\n",
      "        ?lexeme wikibase:lexicalCategory ?lexical_category .\n",
      "      }\n",
      "    ?lexeme ontolex:lexicalForm ?form .\n",
      "    ?form ontolex:representation ?formLab .\n",
      "    }Group by ?lexeme ?lexical_category ?form\n",
      "  } AS %results\n",
      "  WHERE {\n",
      "    INCLUDE %results\n",
      "    OPTIONAL {\n",
      "      ?lexical_category rdfs:label ?lexical_categoryLabel .\n",
      "      FILTER (LANG(?lexical_categoryLabel) = \"en\")\n",
      "    }\n",
      "    # SERVICE does not work!?\n",
      "    # SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" . }\n",
      "  }\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(getAncient(\"SUX\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(endpoint_url, query) :\n",
    "    user_agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1])\n",
    "    # TODO adjust user agent; see https://w.wiki/CX6\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "def queryFunc(lang, char) :\n",
    "    queryOne = '''\n",
    "# tool: ordia\n",
    "# title: List of lexemes for a language\n",
    "SELECT\n",
    "  ?lexeme ?lexemeLabel ?form ?formlabel\n",
    "  ?lexical_category ?lexical_categoryLabel\n",
    "WITH {\n",
    "  SELECT ?lexeme (GROUP_CONCAT(DISTINCT ?lexemeLab; SEPARATOR = \" // \") AS ?lexemeLabel) ?lexical_category ?form (GROUP_CONCAT(DISTINCT ?formLab; SEPARATOR = \" // \") AS ?formlabel) WHERE {'''\n",
    "    queryTwo = f'''\n",
    "    ?lexeme a ontolex:LexicalEntry ;\n",
    "            dct:language wd:{language_to_QID.get(lang)} ;\n",
    "            wikibase:lemma ?lexemeLab .\n",
    "    FILTER(STRSTARTS(?formLab, \"'''\n",
    "\n",
    "\n",
    "    queryThree = f\"{char}\"\n",
    "\n",
    "\n",
    "    queryFour = '''\"))\n",
    "    OPTIONAL {\n",
    "      ?lexeme wikibase:lexicalCategory ?lexical_category .\n",
    "    }\n",
    "   ?lexeme ontolex:lexicalForm ?form .\n",
    "   ?form ontolex:representation ?formLab .\n",
    "  }Group by ?lexeme ?lexical_category ?form\n",
    "} AS %results\n",
    "WHERE {\n",
    "  INCLUDE %results\n",
    "  OPTIONAL {\n",
    "    ?lexical_category rdfs:label ?lexical_categoryLabel .\n",
    "    FILTER (LANG(?lexical_categoryLabel) = \"en\")\n",
    "  }\n",
    "  # SERVICE does not work!?\n",
    "  # SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" . }\n",
    "}\n",
    "'''\n",
    "    return queryOne + queryTwo + queryThree + queryFour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_To_DF_With_Char(lang, char):\n",
    "  results = get_results(endpoint_url, queryFunc(lang, char))\n",
    "  resultsList = []\n",
    "  for result in results[\"results\"][\"bindings\"]:\n",
    "      key = list(result.keys())\n",
    "      values = [i.get(\"value\") for i in list(result.values())]\n",
    "      rowDict = {}\n",
    "      for key, value in zip(key, values):\n",
    "        rowDict.update({key : value})\n",
    "      resultsList.append(rowDict)\n",
    "  df = pd.DataFrame(resultsList)\n",
    "  return df\n",
    "\n",
    "def query_To_DF(query):\n",
    "  results = get_results(endpoint_url, query)\n",
    "  resultsList = []\n",
    "  for result in results[\"results\"][\"bindings\"]:\n",
    "      key = list(result.keys())\n",
    "      values = [i.get(\"value\") for i in list(result.values())]\n",
    "      rowDict = {}\n",
    "      for key, value in zip(key, values):\n",
    "        rowDict.update({key : value})\n",
    "      resultsList.append(rowDict)\n",
    "  df = pd.DataFrame(resultsList)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forms(lang) :\n",
    "    \"\"\"\n",
    "    This function takes a language and returns all the Wikidata form data as a data frame. \n",
    "    The data frame contains the following columns: \"lexeme\", \"lexemeLabel\", \"form\", \"formlabel\", \"lexical_category\", and \"lexical_categoryLabel\"\n",
    "\n",
    "    Parameters:\n",
    "    param1 (str): Must be the ISO code for the following languages: Akkadian (AKK), Arabic (AR), Czech (CS), German (DE), English (EN), French (FR), Hebrew (HE), Hittite (HIT), Italian (IT), Sumerian (SUX), Turkish (TR), Latin (LA)\n",
    "\n",
    "    Returns:\n",
    "    pandas.core.frame.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    alphabet = string.ascii_lowercase + string.ascii_uppercase\n",
    "    accents = 'àâäæçéèêëîïôœùûüÿÀÂÄÆÇÉÈÊËÎÏÔŒÙÛÜŸ'\n",
    "    special_chars = 'äöüßÄÖÜŒéàăŪñãõ'\n",
    "    numbers = '1234567890'\n",
    "    symbols = \"-`å¨'.,/¿¡@€£¢$!?&~#\"\n",
    "\n",
    "    romance_chars = alphabet + accents + special_chars + numbers + symbols\n",
    "\n",
    "\n",
    "    hebrew_alphabet = [\n",
    "    'א', 'ב', 'ג', 'ד', 'ה', 'ו', 'ז', 'ח', 'ט', 'י',\n",
    "    'כ', 'ך', 'ל', 'מ', 'ם', 'נ', 'ן', 'ס', 'ע', 'פ',\n",
    "    'ף', 'צ', 'ץ', 'ק', 'ר', 'ש', 'ת',\n",
    "    '׳', '״', 'ֽ', '׀', '—', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0'\n",
    "    ]\n",
    "\n",
    "    czech_alphabet = (\n",
    "    \"aábcčdďeéěfghichíjklmnňoópqrřsštťuúůvwxyzž\" +\n",
    "    \"AÁBCČDĎEÉĚFGHICHÍJKLMNOPQRSŘŠTŤUÚŮVWXYZŽ\" +\n",
    "    \"1234567890-`å¨'.,/¿¡@€£¢$!?&~#\"\n",
    "    )\n",
    "\n",
    "    if lang == \"SUX\" or lang == \"AKK\" or lang == \"TR\" or lang == \"HIT\" or lang == \"AR\":\n",
    "        query = getShortLang(lang)\n",
    "        return query_To_DF(query)\n",
    "    else :\n",
    "        df_accumulator = []\n",
    "        if lang == \"CS\" :\n",
    "            for i in czech_alphabet :\n",
    "                df_accumulator.append(query_To_DF_With_Char(lang, i))\n",
    "        if lang == \"HE\" :\n",
    "            for i in hebrew_alphabet :\n",
    "                df_accumulator.append(query_To_DF_With_Char(lang, i))\n",
    "        else :\n",
    "            for i in romance_chars :\n",
    "                df_accumulator.append(query_To_DF_With_Char(lang, i))\n",
    "        return pd.concat(df_accumulator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
